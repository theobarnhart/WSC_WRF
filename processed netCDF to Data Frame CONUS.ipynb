{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import glob as glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n"
     ]
    }
   ],
   "source": [
    "# compute annual runoff by differencing the first and last accumulation surfaces\n",
    "\n",
    "years = np.arange(2002,2014) # water years 2002-2013\n",
    "\n",
    "for year in years:\n",
    "    strtfl = '/Volumes/data/wrf/%s/wrf2d_d01_%s-09-30_thinned_crop.nc'%(year-1,year-1)\n",
    "    endfl = '/Volumes/data/wrf/%s/wrf2d_d01_%s-09-30_thinned_crop.nc'%(year,year)\n",
    "    \n",
    "    start = Dataset(strtfl,'r')\n",
    "    end = Dataset(endfl,'r')\n",
    "    \n",
    "    gw = np.array(end.variables['UDROFF']) - np.array(start.variables['UDROFF'])\n",
    "    ro = np.array(end.variables['SFROFF']) - np.array(start.variables['SFROFF'])\n",
    "    \n",
    "    np.savez_compressed('./data/runoff_wy%s.npz'%(year),ro)\n",
    "    np.savez_compressed('./data/groundwater_wy%s.npz'%(year),gw)\n",
    "    \n",
    "    print year\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365\n",
      "Processed Water Year 2002\n",
      "365\n",
      "Processed Water Year 2003\n",
      "366\n",
      "Processed Water Year 2004\n",
      "365\n",
      "Processed Water Year 2005\n",
      "365\n",
      "Processed Water Year 2006\n",
      "365\n",
      "Processed Water Year 2007\n",
      "366\n",
      "Processed Water Year 2008\n",
      "365\n",
      "Processed Water Year 2009\n",
      "365\n",
      "Processed Water Year 2010\n",
      "365\n",
      "Processed Water Year 2011\n",
      "366\n",
      "Processed Water Year 2012\n",
      "365\n",
      "Processed Water Year 2013\n"
     ]
    }
   ],
   "source": [
    "## Processed Clipped Model Output\n",
    "\n",
    "years = np.arange(2002,2014) # water years 2002-2013\n",
    "\n",
    "for year in years:\n",
    "\n",
    "    days = pd.date_range(start='10-01-'+str(year-1),end='09-30-'+str(year),freq='D')\n",
    "\n",
    "    files = []\n",
    "    for d in days: #loop through days and append to file list\n",
    "        files.append('/Volumes/data/wrf/%s/wrf2d_d01_%s_thinned_crop.nc'%(d.year,d.strftime('%Y-%m-%d')))\n",
    "\n",
    "    n = len(files) # number of files\n",
    "    d,h,w = np.array(Dataset(files[0],'r').variables['QSNBOT']).shape # get the shape of the array\n",
    "\n",
    "    snowmelt = np.empty((n,h,w)) # preallocate numpy arrays\n",
    "    #runoff = np.empty((1,h,w))\n",
    "    #groundwater = runoff.copy()\n",
    "    \n",
    "    \n",
    "    # preload the time slice before for accumulated variables\n",
    "    #gw = np.array(Dataset('/Volumes/data/wrf/%s/wrf2d_d01_%s-09-30_thinned_crop.nc'%(year-1,year-1)).variables['UDROFF'])\n",
    "    #ro = np.array(Dataset('/Volumes/data/wrf/%s/wrf2d_d01_%s-09-30_thinned_crop.nc'%(year-1,year-1)).variables['SFROFF'])\n",
    "\n",
    "    ct = 0\n",
    "    for fl in files:\n",
    "        tmp = Dataset(fl,'r')        \n",
    "        snowmelt[ct] = np.array(tmp.variables['QSNBOT']) * (60.*60.*24.) # mm/s >> mm/minute >> mm/hour >> mm/day\n",
    "        #runoff += (np.array(tmp.variables['SFROFF'])-ro) # mm/day\n",
    "        #groundwater += (np.array(tmp.variables['UDROFF'])-gw) # mm/day\n",
    "        ct += 1 # increment counter\n",
    "        #gw = np.array(tmp.variables['UDROFF'])\n",
    "        #ro = np.array(tmp.variables['SFROFF'])\n",
    "        \n",
    "    # compute averages \n",
    "    \n",
    "    #runoff /= ct # mm/day\n",
    "    #groundwater /= ct # mm/day\n",
    "    print ct\n",
    "    np.savez_compressed('./data/snowmelt_wy%s.npz'%(year),snowmelt)\n",
    "    #np.savez_compressed('./data/runoff_wy%s.npz'%(year),runoff)\n",
    "    #np.savez_compressed('./data/groundwater_wy%s.npz'%(year),groundwater)\n",
    "    print 'Processed Water Year %s'%(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n"
     ]
    }
   ],
   "source": [
    "## Processed Clipped Precip Data\n",
    "\n",
    "years = np.arange(2002,2014) # water years 2002-2013\n",
    "for year in years:\n",
    "    days = pd.date_range(start='10-01-'+str(year-1),end='09-30-'+str(year),freq='M')\n",
    "    \n",
    "    files = []\n",
    "    \n",
    "    for d in days: #loop through days and append to file list\n",
    "        files.append('/Volumes/data/wrf/precip/daily/wrf2d_d01_daily_tot_%s_crop.nc'%(d.strftime('%Y%m')))\n",
    "    \n",
    "    n = len(pd.date_range(start='10-01-'+str(year-1),end='09-30-'+str(year),freq='D'))\n",
    "    d,h,w = np.array(Dataset(files[0],'r').variables['ACRAINLSM']).shape\n",
    "    ct1 = 0 # counter 1\n",
    "    ct2 = 0 # counter 2\n",
    "    rain = np.empty((n,h,w)) # preallocate numpy array\n",
    "    precip = np.empty((1,h,w))\n",
    "    \n",
    "    for fl in files:\n",
    "        #print ct2\n",
    "        tmp = Dataset(fl,'r')\n",
    "        tmp2 = np.array(tmp.variables['ACRAINLSM']) # pull out rain\n",
    "        n,h,w = tmp2.shape # get rain dimensions\n",
    "        rain[ct2:ct2+n,:,:] = tmp2 # add rain to the preallocated array\n",
    "        precip += np.array(tmp.variables['PREC_ACC_NC']).sum(axis=0) # add total monthly precip to the precip data frame\n",
    "        ct1 += 1 # increment counter\n",
    "        ct2 += n # add the length of the month to the second counter\n",
    "\n",
    "    # compute averages \n",
    "    #precip /= ct2 # divide by number of days to get mm/day\n",
    "    #print ct2\n",
    "    np.savez_compressed('./data/rain_wy%s'%(year),rain)\n",
    "    np.savez_compressed('./data/precip_wy%s'%(year),precip)\n",
    "    print year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the cell indexer\n",
    "indexer = np.load('./data/index.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a function to convert the numpy data files to a giant data frame\n",
    "def load_data(wflux,surf,base,rain,snowmelt,precip,year,idx):\n",
    "    '''\n",
    "    wflux = water flux (rain + snowmelt)\n",
    "    surf = surface runoff\n",
    "    base = baseflow\n",
    "    year = water year\n",
    "    idx = indexer\n",
    "    \n",
    "    Function to reshape input data and append it onto the larger data frame\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    m,p = np.shape(wflux)\n",
    "    wflux = np.reshape(wflux,(m*p))\n",
    "    surf = np.reshape(surf,(m*p))\n",
    "    base = np.reshape(base,(m*p))\n",
    "    rain = np.reshape(rain,(m*p))\n",
    "    snowmelt = np.reshape(snowmelt,(m*p))\n",
    "    precip = np.reshape(precip,(m*p))\n",
    "    year = np.repeat(year,m*p)\n",
    "    idx = np.reshape(idx,(m*p))\n",
    "    \n",
    "    # return a data frame of the input data to be appended onto the mother data frame\n",
    "    return pd.DataFrame({'idx':idx,'wyear':year,'wflux':wflux,'runoff':surf,'baseflow':base,\n",
    "                         'rain':rain,'snowmelt':snowmelt,'precip':precip})\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n"
     ]
    }
   ],
   "source": [
    "# numpy files to data frame\n",
    "wateryears = np.arange(2002,2014) \n",
    "\n",
    "df = pd.DataFrame()\n",
    "for year in wateryears:\n",
    "    wflux = np.load('./data/waterflux_wy%s.npy'%year)\n",
    "    surf = np.load('./data/runoff_wy%s.npz'%year)['arr_0']\n",
    "    base = np.load('./data/groundwater_wy%s.npz'%year)['arr_0']\n",
    "    rain = np.load('./data/processedrain_wy%s.npy'%year)\n",
    "    snowmelt = np.load('./data/processedsnowmelt_wy%s.npy'%year)\n",
    "    precip = np.load('./data/precip_wy%s.npz'%year)['arr_0']\n",
    "    df = df.append(load_data(wflux,surf,base,rain,snowmelt,precip,year,indexer))\n",
    "    print year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_pickle('./data/wrf_data.df') # save the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
